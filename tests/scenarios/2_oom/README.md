# 시나리오 2: OOM(Out of Memory) 발생 시 파일 손상

## 🔍 문제 설명

대용량 데이터를 저장하는 중 시스템 메모리가 부족해지면, 프로세스가 OOM(Out Of Memory)으로 강제 종료될 수 있습니다.  
이때 `df.to_parquet()` 또는 `pl.write_parquet()`로 저장 중이던 파일이 깨진 상태로 남아, 후속 파이프라인에서 다음과 같은 문제가 발생할 수 있습니다:

- `.parquet` 파일이 비어 있거나 손상되어 읽기 불가능
- 분석 결과 왜곡
- 전체 파이프라인 실패
- 디버깅 시간 증가

## ⚠️ before.py

- 일반 pandas.to_parquet() 또는 polars.write_parquet() 사용
- 저장 중 OOM 발생 시, 깨진 .parquet 파일이 남을 수 있음
- 실패 시 예외 처리 또는 롤백 없음
- 후속 시스템에서 파일을 읽으려다 오류 발생

## ✅ after.py

- atomicwriter 라이브러리 사용
- 임시 디렉토리에 먼저 저장한 후, 성공적으로 완료되었을 때만 대상 파일로 이동
- 저장 중 OOM 발생 시, 임시 파일만 남고 대상 파일은 보존됨
- 결과적으로 `.parquet` 파일의 무결성이 유지되고 후속 파이프라인이 안전함

## 💡 테스트 방법

1. `before.py`를 실행한 뒤, 시스템 메모리를 강제로 압박하거나 제한된 환경에서 실행
2. OOM이 발생해도 `data/oom_output.parquet` 파일이 남아 있는지, 깨졌는지 확인
3. 같은 조건에서 `after.py` 실행
4. `data/oom_output.parquet` 파일이 생성되지 않았거나, 이전 파일이 그대로 보존되었는지 확인
